{"cells":[{"cell_type":"markdown","metadata":{"id":"hf5gYZPVn48e"},"source":["**Installing Packages**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n5bB9rIFSWSJ"},"outputs":[],"source":["%pip install --quiet --upgrade discord.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-LO0E8Jauo2"},"outputs":[],"source":["%pip install --quiet --upgrade transformers accelerate torch"]},{"cell_type":"markdown","metadata":{"id":"7L3KCMz0oD0s"},"source":["**Importing Utilities**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7vu56UAIGD0"},"outputs":[],"source":["from google.colab import userdata\n","from huggingface_hub import login\n","import os, gc, re, discord, asyncio, random\n","\n","# HuggingFace Token\n","hf_token = userdata.get('HF_Read_Token')\n","\n","# Discord Tokens\n","app_id = userdata.get(\"APP_ID\")\n","public_key = userdata.get(\"Public_KEY\")\n","discord_token = userdata.get(\"Discord_SECRET_KEY\")\n","channel_id = int(userdata.get(\"Channel_ID\"))\n","\n","login(token=hf_token)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F21iSKLHBELn"},"outputs":[],"source":["from copy import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xeprY28BeK1d"},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM, pipeline"]},{"cell_type":"markdown","metadata":{"id":"Ol1Dt88soLsc"},"source":["Initializing Variables and Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-OttxZJz-u6w"},"outputs":[],"source":["def clear_cache():\n","  gc.collect()\n","  torch.cuda.empty_cache()\n","  print(\"\\n\\nCleared GPU Cache\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4tS4a5JVa8Md"},"outputs":[],"source":["model_name: str = \"microsoft/Phi-3.5-mini-instruct\"\n","\n","is_cuda: bool = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if is_cuda else \"cpu\")\n","\n","print(\"Using device:\", device)\n","print(\"Using model:\", model_name)"]},{"cell_type":"markdown","metadata":{"id":"RgPA7WgXoRos"},"source":["Pretraining the AI Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wT5-ecLogs8"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, use_fast=True)\n","\n","print(\"Initialized Tokenizer\")\n","\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    token=hf_token,\n","    device_map=\"auto\",\n","    dtype=torch.float16\n",")\n","\n","print(\"Pretrained the Model\")\n","\n","clear_cache()"]},{"cell_type":"markdown","metadata":{"id":"zW04_3O-JNvL"},"source":["**Code Starts Here**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V-U1vYJ8BNOA"},"outputs":[],"source":["def generate_code(prompt: str, max_tokens: int=200, min_tokens: int=10) -> str:\n","  tokenized_prompt = tokenizer(\n","      prompt,\n","      return_tensors=\"pt\"\n","  ).to(device)\n","\n","  output_tokens = model.generate(\n","          **tokenized_prompt,\n","          do_sample=False,\n","          # temperature=0.7,\n","          # top_p=0.95,\n","          pad_token_id=tokenizer.eos_token_id,\n","          eos_token_id=tokenizer.eos_token_id,\n","          max_new_tokens=max_tokens,\n","          min_new_tokens=min_tokens\n","  )\n","\n","  outputs = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n","\n","  outputs = outputs[len(prompt):]\n","\n","  triple_backtick_index: int = outputs.find(\"```\")\n","  if triple_backtick_index >= 0:\n","    outputs = outputs[:triple_backtick_index]\n","\n","  return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ygEp0GWPig7n"},"outputs":[],"source":["intros: list[str] = [\n","    \"Alright bro! Here it is:\",\n","    \"Got you covered, check this out:\",\n","    \"Hereâ€™s what I cooked up for you:\",\n","    \"No worries, try this:\",\n","    \"Okay, this should do the trick:\",\n","    \"Hereâ€™s a clean solution:\",\n","    \"Check this out, bro:\",\n","    \"Done! Hereâ€™s the code:\"\n","]\n","\n","outros: list[str] = [\n","    \"Hope that helps!\",\n","    \"Let me know if you need tweaks.\",\n","    \"That should work fine.\",\n","    \"Give it a shot and tell me how it goes.\",\n","    \"You can build on this if needed.\",\n","    \"Thatâ€™s one way to do it!\",\n","    \"Try running this and see.\",\n","    \"Hope this clears things up!\"\n","]\n","\n","greetings: list[str] = [\n","    \"Yo broskis, I'm online now ğŸš€\",\n","    \"Guess who just woke up? ğŸ˜\",\n","    \"Your friendly neighborhood bot has arrived ğŸ¤–\",\n","    \"I'm live and kicking, let's code! ğŸ’»\",\n","    \"Reporting for duty, boss! ğŸ«¡\",\n","    \"Back online, ready to roll ğŸ”¥\",\n","    \"Botâ€™s in da house ğŸ‰\",\n","    \"Systems online. Letâ€™s get to work. âš¡\",\n","    \"Wassup fam, I'm here ğŸ™Œ\",\n","    \"Ready when you are! ğŸ‘Š\"\n","]\n","\n","goodbyes: list[str] = [\n","    \"Shutting down, catch you later broskis ğŸ‘‹\",\n","    \"Bot out! ğŸ’¨\",\n","    \"Logging off, stay awesome fam âœŒï¸\",\n","    \"Powering down... see you soon ğŸ”Œ\",\n","    \"Thatâ€™s all for now, peace out ğŸ¤–\",\n","    \"Iâ€™m off, donâ€™t miss me too much ğŸ˜\",\n","    \"Goodbye world ğŸŒ\",\n","    \"Mission complete, going offline ğŸ«¡\",\n","    \"Disconnecting... until next time â³\",\n","    \"Later gators ğŸŠ\"\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"05xxZq2FSos0"},"outputs":[],"source":["clear_cache()\n","\n","class MyClient(discord.Client):\n","    max_tokens: int = 300\n","\n","    async def on_ready(self):\n","        print(f'Logged on as {self.user}!')\n","        channel = self.get_channel(channel_id)\n","        print(channel_id, channel, sep=\"\\n\")\n","        if channel:\n","          print(\"Channel Found\")\n","          await channel.send(\"Yo bro, I'm online and ready to code! ğŸš€\")\n","\n","    async def on_message(self, message):\n","        prompt: str = re.sub(r\"<[@#&][0-9]+>\", \"\", message.content).strip()\n","        print(f'Message from {message.author}: {prompt}')\n","\n","        if message.author == self.user or not self.user in message.mentions:\n","            return\n","\n","        Channel = message.channel\n","        exit_post_execution: bool = False\n","\n","        # Processing exit prompt\n","        if re.search(r\"^exit\", prompt, re.IGNORECASE):\n","            await Channel.send(f\"{random.choice(goodbyes)}\")\n","            await Channel.send(\"Exiting...\")\n","            await self.close()\n","            return\n","\n","        if re.search(r\"\\nexit$\", prompt, re.IGNORECASE):\n","            exit_post_execution = True\n","            prompt = re.sub(r\"\\nexit$\", \"\", prompt, flags=re.IGNORECASE).strip()\n","\n","        # Matching for tokens\n","        pre_matching = re.search(r\"^\\s*tokens?\\s*=\\s*(\\d+)\\s*\\b\", prompt, re.IGNORECASE)\n","        post_matching = re.search(r\"\\ntokens?\\s*=\\s*(\\d+)\\s*\\b$\", prompt, re.IGNORECASE)\n","        print(\"pre_matching=\", pre_matching, sep=\"\")\n","        print(\"post_matching=\", post_matching, sep=\"\")\n","\n","        # Setting max_tokens as per user input\n","        if pre_matching:\n","            self.max_tokens = int(pre_matching.group(1))\n","            print(f\"max_new_tokens reset to {self.max_tokens}\")\n","            prompt = prompt.replace(pre_matching.group(0), \"\").strip()\n","            await Channel.send(f\"max_new_tokens reset to {self.max_tokens}\")\n","\n","        if post_matching:\n","          prompt = prompt.replace(post_matching.group(0), \"\").strip()\n","\n","        if prompt.strip():\n","            print(\"Generating on prompt:\", prompt)\n","            async with Channel.typing():\n","              code = await asyncio.to_thread(generate_code, prompt, self.max_tokens)\n","            await Channel.send(f\"{random.choice(intros)}:\\n```\\n{code}\\n```\\n{random.choice(outros)}\")\n","        elif not pre_matching and not post_matching:\n","            await Channel.send(\"Yo bro, gimme a valid input\")\n","\n","        # Setting tokens if set at end\n","        if post_matching:\n","            self.max_tokens = int(post_matching.group(1))\n","            print(f\"max_new_tokens reset to {self.max_tokens}\")\n","            await Channel.send(f\"max_new_tokens reset to {self.max_tokens}\")\n","\n","        # Exiting if exit at end\n","        if exit_post_execution:\n","            await Channel.send(f\"{random.choice(goodbyes)}\")\n","            await Channel.send(\"Exiting...\")\n","            await self.close()\n","\n","\n","intents = discord.Intents.default()\n","intents.message_content = True\n","intents.guilds = True  # needed for guild/channel info\n","intents.members = True # optional, but often useful\n","\n","client = MyClient(intents=intents)\n","await client.start(discord_token)"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPofJA5gIh2bgkBL+q5bp/8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}